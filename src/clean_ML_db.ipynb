{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens database cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract needed dates\n",
    "\n",
    "According to its ReadMe, this database has records from ratings dating from between January 09, 1995 and March 31, 2015. The Netflix database only ranges from October 1998 to December 2005, so that many entries are useless.\n",
    "\n",
    "The numbers of distinct users goes from 138,493 to 52,875."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.read_csv(\"data/MovieLens/ratings.csv\", header=None, encoding=\"UTF-8\", names=[\"userId\",\"movieId\",\"rating\",\"timestamp\"])\n",
    "print(db.shape)\n",
    "\n",
    "# Create the start and stop boundaries for the timestamp\n",
    "# format: seconds elapsed since 1st Jan 1970\n",
    "start_date =  time.mktime(datetime(1998,10,1).timetuple())\n",
    "end_date =  time.mktime(datetime(2006,1,1).timetuple())\n",
    "\n",
    "# Remove out-of-bounds entries\n",
    "a = (db[\"timestamp\"] < start_date) \n",
    "print(\"There are\", sum(a), \"reviews made before the 1st October 1998.\")\n",
    "b = (db[\"timestamp\"] > end_date) \n",
    "print(\"There are\", sum(b), \"reviews made after the 31st December 2005.\")\n",
    "\n",
    "db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of distincts users\n",
    "list_ml_movies = db.movieId.unique()\n",
    "print(\"There are\", len(db.userId.unique()), \"users left.\")\n",
    "print(\"There are\", len(db.movieId.unique()), \"movies left.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove not matching movies\n",
    "\n",
    "Only the movies that are present in both datasets need to be kept, the other ones would not be taken into account in the scoring functio anyway. \n",
    "\n",
    "In the process, also make the movieIDs consistent across the two databases so that the titles do not need to be processed anymore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract movie titles\n",
    "import csv\n",
    "\n",
    "# These titles are present several times and cannot be uniquely identified\n",
    "wrong_movies = [\"pinocchio(2002)\", \"lastmanstanding(1996)\", \"emma(1996)\",\n",
    "                \"hamlet(2000)\", \"hamlet(1990)\", \"menwithguns(1997)\",\n",
    "                \"thehunchbackofnotredame(1999)\",\"thelucyshow(1962)\",\n",
    "                \"stranded(2002)\",\"frankenstein(2004)\",\"secondskin(2000)\",\n",
    "                \"elvira'shorrorclassics(1959)\",\"waroftheworlds(2005)\",\n",
    "                \"chaos(2005)\",\"offside(2006)\",\"blackout(2007)\",\"thegirl(2012)\",\n",
    "                \"crimewave(1985)\",\"20,000leaguesunderthesea(1997)\",\n",
    "                \"aladdin(1992)\",\"beneath(2013)\",\"thedisappeared(2008)\",\n",
    "                \"paradise(2013)\",\"clearhistory(2013)\",\"casanova(2005)\",\n",
    "                \"johnnyexpress(2014)\",\"darling(2007)\"]\n",
    "nf_movies = {};\n",
    "with open('data/Netflix/movie_titles.txt', encoding=\"ISO-8859-1\") as nf:\n",
    "    for col1,col2,*col3 in csv.reader(nf):\n",
    "        #s = ''.join(col3).lower().replace(\" \",\"\")\n",
    "        #s = s[:(s.find('(') if s.find('(') !=-1 else len(s))]\n",
    "        s = (''.join(col3)+\"(\"+col2+\")\").lower().replace(\" \",\"\")\n",
    "        if s not in wrong_movies:\n",
    "            nf_movies[s] = int(col1)\n",
    "nf_movies = pd.Series(nf_movies, name='Netflix')\n",
    "\n",
    "ml_movies = {};\n",
    "with open('data/MovieLens/movies.csv', encoding=\"UTF-8\") as ml:\n",
    "    for col1,col2,*col3 in csv.reader(ml):\n",
    "        if int(col1) in list_ml_movies:\n",
    "            s = ''.join(col2).lower().replace(\" \",\"\")\n",
    "            loc = s.find(\",the(\")\n",
    "            if loc !=-1:\n",
    "                s = \"the\" + s[:loc] + s[loc+4:]\n",
    "            else:\n",
    "                loc=s.find(\",a(\")\n",
    "                if loc != -1:\n",
    "                    s = \"a\" + s[:loc] + s[loc+2:] \n",
    "                else:\n",
    "                    loc=s.find(\",an(\")\n",
    "                    if loc != -1:\n",
    "                        s = \"an\" + s[:loc] + s[loc+3:]\n",
    "            if s not in wrong_movies:\n",
    "                ml_movies[s] = int(col1)\n",
    "\n",
    "ml_movies = pd.Series(ml_movies, name='MovieLens')\n",
    "print(len(nf_movies))\n",
    "print(len(ml_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find intersection of movie lists using title+date\n",
    "common_movies = nf_movies.index.intersection(ml_movies.index)\n",
    "matches = pd.Series(data=ml_movies.loc[common_movies].values,index=nf_movies.loc[common_movies].values)\n",
    "matches.name = 'ml_movieId'\n",
    "matches.index.name = 'nf_movieId'\n",
    "print('There is', matches.shape[0], 'matches')\n",
    "display(matches.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard non matches\n",
    "db = db.loc[db['movieId'].isin(matches),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = []\n",
    "#df = pd.DataFrame(columns=[\"userId\",\"movieId\",\"rating\",\"timestamp\"])\n",
    "for i in matches.index:\n",
    "    tmp = pd.read_csv(\"data/Netflix/training_set/mv_\" + format(i,'07d')+\".txt\", header=None,\n",
    "                         names=[\"userId\",\"rating\",\"timestamp\"],encoding=\"ISO-8859-1\")\n",
    "    tmp[\"movieId\"] = matches[i]\n",
    "    z.append(tmp)\n",
    "df = pd.concat(z,copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "assert db.movieId.unique().shape[0] == df.movieId.unique().shape[0] == matches.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"DF.csv\",\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.to_csv(\"DB.csv\",\";\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
